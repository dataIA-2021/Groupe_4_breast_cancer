{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49866e07",
   "metadata": {},
   "source": [
    "# Introduction à la classification binaire\n",
    "# Application au diagnostic du cancer du sein\n",
    "\n",
    "Travail en groupe 3/4, sur la semaine 50\n",
    "\n",
    "## Projet Breast Cancer Wisconsin\n",
    "Les données: \n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "Nous allons étudier le concept de classification qui est avec la régression l'autre tâche principale du Machine Learning supervisé. Nous allons particulièrement nous concentrer sur la classification binaire et l'illustrer sur un exemple d'application concret, le diagnostic du cancer du sein. En outre, nous allons découvrir et utiliser la régression logistique comme modèle de Machine Learning pour effectuer notre tâche de classification binaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d6101",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "Le Breast Cancer Wisconsin (diagnostic) Dataset est un jeu de données classique du Machine Learning. Il est composé de 569 exemples, chaque exemple étant défini par 30 caractéristiques ; ces caractéristiques correspondent principalement aux propriétés géométriques mesurées sur les cellules issues de la biopsie. Chaque exemple est classé dans la catégorie \"Benign\" (n=357) si la tumeur est bénigne et dans la catégorie \"Malignant\" (n=212) si la tumeur est maline. Le nombre de catégories de la classification est de 2, on parle alors de classification binaire. La finalité de ce travail est ainsi d'entrainer un modèle de Machine Learning à identifier le type de tumeur (bénigne ou maline) en fonction des propriétés géométriques mesurées sur les cellules issues de la biopsie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd6423",
   "metadata": {},
   "source": [
    "### concepts de base de la classification binaire :\n",
    "Lister:\n",
    "\n",
    "    En quoi consiste la classification binaire ?\n",
    "    Qu'est-ce qu'une matrice de confusion ?\n",
    "        Qu'est-ce qu'un faux négatif ? un vrai négatif ? un faux positif ? un vrai positif ?\n",
    "    Qu'est-ce que le taux de classification (accuracy) ?\n",
    "    Qu'est-ce que le rappel (recall) ?\n",
    "    Qu'est-ce que la précision (precision) ?\n",
    "    Qu'est-ce que le F1-score ?\n",
    "    Qu'est-ce qu'une courbe ROC ?\n",
    "        Qu'est-ce que l'Area Under the Curve (AUC) ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1d273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318b39db",
   "metadata": {},
   "source": [
    "### Etude\n",
    "décrire:\n",
    "\n",
    "    Qu'est-ce qu'une régression logistique ?\n",
    "    Qu'est-ce que le Feature Scaling ?\n",
    "        A quoi sert-il et quels sont ses avantages ?\n",
    "        Qu'est-ce que la normalisation des données ?\n",
    "        Qu'est-ce que la standardisation des données ?\n",
    "        Comment l'utilise-t-on lorsque l'on a un jeu de train et un jeu de test ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015b96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125beb23",
   "metadata": {},
   "source": [
    "## Implémentation python\n",
    "Entrainement d'un modèle de type régression logistique à diagnostiquer l'absence ou la présence d'un cancer du sein\n",
    "Les étapes:\n",
    "\n",
    "    Importation des librairies Python\n",
    "    Chargement des données du Breast Cancer Wisconsin (diagnostic) Dataset\n",
    "    Mise au format Numpy des données\n",
    "        Par défaut, patients sains = 0, patients malades = 1.\n",
    "    Echantillonnage des données\n",
    "        NB test_size = 113\n",
    "    Afficher sous forme d'histogrammes la distribution du jeu de données initial, du jeu de train et du jeu de test en fonction de chaque catégorie (bénigne et maline)\n",
    "    Effectuer le Feature Scaling\n",
    "    Entrainer le modèle de régression logistique\n",
    "        model = LogisticRegression(C = 0.1, max_iter = 10000)\n",
    "    Calculer et afficher les performances obtenues sur le jeu d'apprentissage\n",
    "        Matrice de confusion\n",
    "        Taux de classification, Rappel, Précision et F1-Score\n",
    "        Courbe ROC, AUC\n",
    "    Calculer et afficher les performances obtenues sur le jeu de test\n",
    "        Matrice de confusion\n",
    "        Taux de classification, Rappel, Précision et F1-Score\n",
    "        Courbe ROC, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a4a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ad4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc791002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50676b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
